{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Word2Vec.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "gXEV4V4vb-dO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/YongBeomKim/nltk_rnd/raw/master/data/test.jpg\">\n",
        "<br/>\n",
        "# **Project4 | word2vec**\n",
        "## **1 데이터 전처리**"
      ]
    },
    {
      "metadata": {
        "id": "-3ezC4-xb-dS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! apt-get update\n",
        "! apt-get install g++ openjdk-8-jdk \n",
        "! pip3  install  nltk konlpy matplotlib gensim \n",
        "\n",
        "! apt-get install fonts-nanum-coding\n",
        "! apt-get install fontconfig\n",
        "! fc-cache -fv\n",
        "! cp /usr/share/fonts/truetype/nanum/Nanum* /usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf/\n",
        "! rm -rf /content/.cache/matplotlib/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HoRTIp18b-da",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "script_text = \"https://raw.githubusercontent.com/YongBeomKim/nltk_tutorial/master/data/movie_memories_of_murder_2003.txt\"\n",
        "font_file = \"/usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf/NanumGothicCoding.ttf\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i8jDmHkHeaoT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl        \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "font_name   = fm.FontProperties(fname=font_file, size=10).get_name()\n",
        "plt.rc('font', family=font_name)\n",
        "fm._rebuild()\n",
        "mpl.rcParams['axes.unicode_minus'] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0HPpkXmb-de",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 텍스트를 줄단위로 끊어서 불러온뒤\n",
        "# Token 단위로, 한글명사들을 추출한다\n",
        "def txtnoun(sentences , skip=False, tags=['Noun'], stem=True, set_tokens=False):\n",
        "\n",
        "    r\"\"\"\n",
        "    살인의 추억 대본의 텍스트 전처리 작업을 진행합니다\n",
        "    :param sentences: 단일한 Text String 데이터를 입력합니다\n",
        "    :param skip: 분류된 Token 중 사용자가 원하는 형태로 변환된 내용을 출력\n",
        "    :param tags: konlpy 로 분류된 품사중 추출하고자 하는 품사를 정의합니다\n",
        "    :param stem: stemming 작업여부를 정의합니다.\n",
        "    :param set_tokens: return 결과를 token list 객체로 출력할지를 정의합니다\n",
        "    :return: set_tokens 내용에 따라 List, String 타입으로 출력합니다\n",
        "    \"\"\"\n",
        "    \n",
        "    import re\n",
        "    from konlpy.tag import Okt\n",
        "    twitter = Okt()\n",
        "    result  = []\n",
        "    sentences = sentences.replace('\\n', '\\n|')\n",
        "    sentences = sentences.split('|')\n",
        "    for content in sentences:\n",
        "        texts      = content.replace('\\n', '') # 해당줄의 줄바꿈 내용 제거\n",
        "        tokenizer  = re.compile(r'[^ ㄱ-힣]+')  # 한글과 띄어쓰기를 제외한 모든 글자를 선택\n",
        "        token_data = tokenizer.sub('', texts)  # 한글과 띄어쓰기를 제외한 모든 부분을 제거\n",
        "        token_data = token_data.split(' ')\n",
        "        sentence   = []\n",
        "\n",
        "        for token in token_data:\n",
        "            # skip 대상이 없을 떄\n",
        "            if skip == False:\n",
        "                chk_tok = twitter.pos(token, stem=stem)\n",
        "                chk_tok = [temp[0]  for temp in chk_tok   if temp[1] in tags]\n",
        "                ckeck   = \"\".join(chk_tok)\n",
        "                if len(ckeck) > 1:\n",
        "                    sentence.append(ckeck)\n",
        "\n",
        "            # skip 내용이 있을 때\n",
        "            else:\n",
        "                if token.strip() in skip.keys():\n",
        "                    result.append(skip[token.strip()])\n",
        "                else:\n",
        "                    chk_tok = twitter.pos(token, stem=stem)\n",
        "                    chk_tok = [temp[0] for temp in chk_tok if temp[1] in tags]\n",
        "                    ckeck   = \"\".join(chk_tok)\n",
        "\n",
        "                    # 전처리가 끝난 결과가 skip에 해당여부 판단\n",
        "                    if ckeck.strip() in skip.keys():\n",
        "                        result.append(skip[ckeck.strip()])\n",
        "                    elif len(ckeck) > 1:\n",
        "                        sentence.append(ckeck)\n",
        "\n",
        "        # 단락별 작업이 끝난 뒤 '\\n'를 덧붙여서 작업을 종료\n",
        "        temp = \"\".join(sentence)\n",
        "        if len(temp) > 1:\n",
        "            sentence = \" \".join(sentence)\n",
        "            sentence += \"\\n\"\n",
        "            result.append(sentence)\n",
        "\n",
        "    if set_tokens == True:\n",
        "        from nltk.tokenize import word_tokenize\n",
        "        set_token = word_tokenize(\" \".join(result))\n",
        "        return list(set(set_token))\n",
        "\n",
        "    else:\n",
        "        return \" \".join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kHVdw8h4b-di",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "skips = {'두만':'박두만', '태윤':'서태윤', '용구':'조용구', '귀옥':'권귀옥', \n",
        "         '희봉':'구희봉', '동철':'신동철', '광호':'백광호', '병순':'조병순', \n",
        "         '해일':'박해일', '광호의':'백광호', '백광호의':'백광호'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "373WlH3kb-dl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "sentences = requests.get(script_text).text\n",
        "sentences[:300]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J19vNtU5b-do",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = txtnoun(sentences, skip=skips, tags=['Noun'])\n",
        "script_file = 'script.txt'\n",
        "with open(script_file, 'w', encoding='utf-8') as file:\n",
        "    file.write(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCVeKGNeb-dr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from gensim.models import word2vec\n",
        "data  = word2vec.LineSentence(script_file)\n",
        "model = word2vec.Word2Vec(data, size=30, window=2, min_count=10, \n",
        "                          hs=1, workers=4, iter=100, sg=1)\n",
        "model_file = \"script.model\"\n",
        "model.save(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GX-eNnrNb-du",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "## **2 Word2Vec 모델의 활용**\n",
        "모델을 활용하여 유력한 범인을 찾아보자!!"
      ]
    },
    {
      "metadata": {
        "id": "mVJOqSkkb-dv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 저장된 학습모델 파일을 불러오기\n",
        "from gensim.models import word2vec\n",
        "model_file = \"script.model\"\n",
        "model = word2vec.Word2Vec.load(model_file)\n",
        "len(model.wv.vocab.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p4Dud4svb-d1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "list(model.wv.index2word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2v7UGbiOb-d3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<br></br>\n",
        "## **4 Word2Vec 모델 내용 확인**\n",
        "모델을 활용하여 유력한 범인을 찾아보자!!"
      ]
    },
    {
      "metadata": {
        "id": "YjFHc5plb-d4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 범인과 관련된 내용 중 사람이름이 안나옴...\n",
        "model.wv.most_similar('범인', topn=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U_Vmd0fMb-d6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 현장과 가장 가깝게 등장한 인물이 1명 등장\n",
        "model.wv.most_similar('현장', topn=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9iJN3JUsb-d8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 현장 과 백광호 와 밀접한 증거들 중에 방해가 되는 내용을 찾는다\n",
        "model.wv.most_similar(['현장','이향숙'], topn=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7NkSRMmzb-d-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 현장 과 백광호 와 밀접한 증거들 중에 방해가 되는 내용을 찾는다\n",
        "model.wv.most_similar(['현장','백광호'], topn=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l_0tCtitb-eB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 현장 과 백광호 와 밀접한 증거들 중에 '참깨밭' 이 계속 방해가 됨\n",
        "# 참깨밭에 백광호가 밀접하게 연결되어 있어서 이를 제외한 분석이 필요\n",
        "model.wv.most_similar(['현장','백광호'], negative=['참깨밭'], topn=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FItcApxAb-eD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 현장 과 백광호 와 밀접한 증거들 중에 '참깨밭' 이 계속 방해가 됨\n",
        "# 참깨밭에 백광호가 밀접하게 연결되어 있어서 이를 제외한 분석이 필요\n",
        "model.wv.most_similar(['현장','백광호'], negative=['참깨밭','이향숙'], topn=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mW08mEe1b-eF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<br></br>\n",
        "## **5 Visulaization**\n",
        "gensim"
      ]
    },
    {
      "metadata": {
        "id": "t1SR9juDb-eG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab = list(model.wv.vocab)\n",
        "X        = model[vocab]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KAqHYQTYb-eJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "tsne    = TSNE(n_components = 2)\n",
        "X_tsne = tsne.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vv0ZkE8vb-eL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(X_tsne, \n",
        "                  index   = vocab, \n",
        "                  columns = ['x', 'y'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NpcAc_mb-eN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "fig  = plt.figure(figsize=(12,12))\n",
        "ax  = fig.add_subplot(1, 1, 1)\n",
        "ax.scatter(df['x'], df['y'])\n",
        "for word, pos in df.iterrows():\n",
        "    ax.annotate(word, pos, fontsize=15)\n",
        "plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lO6cpA3tb-eP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<br></br>\n",
        "## **6 결과의 해석 및 활용**\n",
        "1. 유사관계, 반대관계로 **출력된 모든 Token들이 가치가 있지는 않다**\n",
        "1. **min_count, Vector 갯수** 2가지 조건만 사용하여 모델을 생성한다\n",
        "1. Word2Vec 도 **문서를 분석하는 도구**에 불과 (절대적 **가치를 창출하는 기법** 으로 오해 X)\n",
        "1. 해당 분야의 **잘 정리된 Document로 학습한 Word2Vec 모델** 에서 **유의미 한 token 들의 관계** 를 Template으로 잘 정리\n",
        "1. 분석대상 문서를 **유사한 조건으로 word2vec 모델** 을 만들고, **앞에서 정리된 Template와** 비교하여 결과\n",
        "다듬기\n",
        "1. 시나리오의 분석 경우\n",
        "    1. 결과물 중 인물의 Token 만 활용하여 분석\n",
        "    1. 결과물 중 증거물의 Token 만 활용하여 분석\n",
        "    1. 결과물 중 장소의 Token 만 활용하여 분석"
      ]
    },
    {
      "metadata": {
        "id": "sZjIqgkkb-eQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model 에 등장하는 인물들\n",
        "charator = [\"박두만\", \"서태윤\", \"조용구\", \"권귀옥\", \"구희봉\", \"신동철\", \"백광호\",\n",
        "            \"조병순\", \"박해일\", \"박보희\", \"이향숙\", \"독고현순\", \"박명자\", \"안미선\", \n",
        "            \"반장\", \"소현\", \"범인\", \"형사\", '괴남자', '순경','피해자', '권기옥','용의자']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J7C-DNFYb-eS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model 에 등장하는 장소명 들\n",
        "area = ['현장', '사무실', '취조실', '변소', '참깨밭', '빗줄기', '어둠속', '언덕집']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72OItVf8b-eU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model 에 등장하는 Item 들\n",
        "items = ['브래지어', '팬티', '우산', '운동화', '스타킹', '목소리', '불빛', '음악', '후레쉬', \n",
        "         '카메라', '라디오', '방송', '유전자', '가방', '코피', '휴지', '신문', '총구']"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}