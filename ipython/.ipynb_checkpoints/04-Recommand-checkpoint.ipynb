{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../data/cosin.png\" width=800>\n",
    "<br/>\n",
    "# **Chapter 4 | 추천시스템**\n",
    "참고사이트 : https://www.machinelearningplus.com/nlp/cosine-similarity/\n",
    "## **1 데이터 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! apt-get update\n",
    "# ! apt-get install g++ openjdk-8-jdk \n",
    "# ! pip3  install  nltk konlpy matplotlib gensim \n",
    "\n",
    "# ! apt-get install fonts-nanum-eco\n",
    "# ! apt-get install fontconfig\n",
    "# ! fc-cache -fv\n",
    "# ! cp /usr/share/fonts/truetype/nanum/Nanum* /usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf/\n",
    "# ! rm -rf /content/.cache/matplotlib/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44506, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     original_title                                           overview  \\\n",
       "0         Toy Story  Led by Woody, Andy's toys live happily in his ...   \n",
       "1           Jumanji  When siblings Judy and Peter discover an encha...   \n",
       "2  Grumpier Old Men  A family wedding reignites the ancient feud be...   \n",
       "\n",
       "              title  \n",
       "0         Toy Story  \n",
       "1           Jumanji  \n",
       "2  Grumpier Old Men  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv('../data/movies_metadata.csv', usecols=['original_title', 'overview', 'title'], low_memory=False)\n",
    "movies = movies.dropna(axis=0)\n",
    "print(movies.shape)\n",
    "\n",
    "movie_plot_li = movies['overview']\n",
    "movie_info_li = movies['title']\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 텍스트 전처리, 모델 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl       = WordNetLemmatizer()\n",
    "        self.tokenizer = RegexpTokenizer('(?u)[A-z]+')\n",
    "    \n",
    "    def __call__(self, doc):  # 클래스 호출시 마다 실행(Tf-idf Vector 호출)\n",
    "        return([self.wnl.lemmatize(t) for t in self.tokenizer.tokenize(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markbaum/Python/python/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런에 위에서 정의한 토크나이저를 입력으로 넣습니다.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer   = TfidfVectorizer(min_df=3, tokenizer=LemmaTokenizer(), stop_words='english')\n",
    "X            = vectorizer.fit_transform(movie_plot_li[:10000]) # 메모리 오류로 갯수를 제한\n",
    "vocabluary   = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.02930725, 0.00580921, ..., 0.01088994, 0.01071711,\n",
       "        0.        ],\n",
       "       [0.02930725, 1.        , 0.05286611, ..., 0.00904565, 0.00890209,\n",
       "        0.        ],\n",
       "       [0.00580921, 0.05286611, 1.        , ..., 0.00466609, 0.00459204,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.01088994, 0.00904565, 0.00466609, ..., 1.        , 0.00860824,\n",
       "        0.        ],\n",
       "       [0.01071711, 0.00890209, 0.00459204, ..., 0.00860824, 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비슷한 영화 추천하는 Cosin 유사모델 만들기\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "movie_sim = cosine_similarity(X)\n",
    "print(movie_sim.shape)\n",
    "movie_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3 코싸인 유사도 테이블 활용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 영화와 유사한 영화목록 출력하기\n",
    "def similar_recommend_by_movie_id(movielens_id, rank=8):\n",
    "    movie_index    = movielens_id - 1\n",
    "    similar_movies = sorted(list(enumerate(movie_sim[movie_index])), key=lambda x:x[1], reverse=True)\n",
    "    print(\"----- {} : 관람객 추천영화 -------\".format(movie_info_li[similar_movies[0][0]]))\n",
    "    for no, movie_idx in enumerate(similar_movies[1:rank]):\n",
    "        print('추천영화 {}순위 : {}'.format(no, movie_info_li[movie_idx[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Money Train : 관람객 추천영화 -------\n",
      "추천영화 0순위 : The Long Good Friday\n",
      "추천영화 1순위 : The January Man\n",
      "추천영화 2순위 : The Milagro Beanfield War\n",
      "추천영화 3순위 : Gone in Sixty Seconds\n",
      "추천영화 4순위 : You Can Count on Me\n",
      "추천영화 5순위 : Anatomy of Hell\n",
      "추천영화 6순위 : Hush!\n",
      "추천영화 7순위 : The Searchers\n",
      "추천영화 8순위 : Rich and Famous\n",
      "추천영화 9순위 : A Face in the Crowd\n",
      "추천영화 10순위 : My Best Fiend\n",
      "추천영화 11순위 : RoboCop 3\n",
      "추천영화 12순위 : H.M.S. Defiant\n",
      "추천영화 13순위 : Lagaan: Once Upon a Time in India\n",
      "추천영화 14순위 : Dracula: Prince of Darkness\n",
      "추천영화 15순위 : The Tuxedo\n",
      "추천영화 16순위 : The Krays\n",
      "추천영화 17순위 : The Southerner\n",
      "추천영화 18순위 : Vatel\n"
     ]
    }
   ],
   "source": [
    "similar_recommend_by_movie_id(20, rank=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
